\chapter*{\huge \centering Abstract}
\addcontentsline{toc}{chapter}{Abstract}

Multiple Sclerosis (MS) is a chronic neurodegenerative disorder characterized by demyelinating lesions in the central nervous system. Accurate and early diagnosis remains challenging due to the disease's complex and heterogeneous nature. This thesis proposes \textbf{MSFusionXAI}, an intelligent multimodal framework integrating \textbf{FLAIR MRI imaging}, clinical data, and explainable artificial intelligence (XAI) techniques for automated MS detection and interpretation.

The framework combines a deep learning based lesion segmentation model (\textbf{ResNet34-UNet}) with an \textbf{adaptive attention-guided fusion module} that jointly analyzes imaging features and clinical biomarkers (age, sex, EDSS, oligoclonal band status). The fused representation enables patient-level classification with \textbf{conditional branching logic}: subjects predicted as healthy terminate processing immediately, while MS predictions trigger automated lesion segmentation and quantification. A \textbf{BioBERT-based explainability module} generates structured natural language reports integrating attention weight distributions, lesion burden metrics, and clinical correlations.

The proposed architecture was evaluated on a clinical dataset from CHU Sahloul University Hospital (46 MS patients, 46 healthy controls) using rigorous five-fold stratified cross-validation. The multimodal fusion model achieved \textbf{93.7\% classification accuracy} ($\pm$2.2\% std), substantially outperforming MRI-only (72.6\%) and clinical-only (89.4\%) baselines. Lesion segmentation reached a \textbf{Dice similarity coefficient of 0.823} with 76.4\% sensitivity and 93.3\% specificity on held-out test data. Attention weight analysis validated clinically meaningful modality prioritization, with MS patients exhibiting significantly higher MRI attention (0.64 $\pm$ 0.18) compared to healthy controls (0.42 $\pm$ 0.22, p < 0.001).

Beyond quantitative results, a key contribution of this work lies in its interpretability. The integration of explainable AI enables the automatic generation of textual summaries highlighting lesion regions and their correlation with disease severity, thereby bridging the gap between deep learning predictions and clinical reasoning.

This thesis demonstrates that combining heterogeneous data modalities within a transparent AI framework can significantly enhance both the accuracy and trustworthiness of MS diagnosis, paving the way for future clinical decision-support systems based on explainable multimodal intelligence.
